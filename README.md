# Blind Image Reasoning System

<div align="center">

ğŸ” **AI-Powered E-Commerce Image Quality Control**

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-green.svg)](https://ultralytics.com/)

</div>

---

## ğŸ¯ Overview

The **Blind Image Reasoning System** is a production-ready quality control system for e-commerce images. It uses a unique "Blind Reasoning" architecture where the LLM Judge **cannot see image pixels directly** - instead, it receives a structured JSON report of extracted features and applies a rulebook to render quality verdicts.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           BLIND IMAGE REASONING SYSTEM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          â”‚    â”‚              SMART FEATURE EXTRACTION                â”‚   â”‚
â”‚  â”‚  INPUT   â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚
â”‚  â”‚  IMAGE   â”‚â”€â”€â”€â–¶â”‚  â”‚ OpenCV  â”‚ â”‚  YOLO   â”‚ â”‚  CLIP   â”‚                â”‚   â”‚
â”‚  â”‚          â”‚    â”‚  â”‚(Tier 3) â”‚ â”‚(Tier 1) â”‚ â”‚(Tier 2) â”‚                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                â”‚   â”‚
â”‚                  â”‚       â”‚           â”‚           â”‚                      â”‚   â”‚
â”‚                  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚   â”‚
â”‚                  â”‚                   â”‚                                  â”‚   â”‚
â”‚                  â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                          â”‚   â”‚
â”‚                  â”‚           â”‚ JSON FEATURES â”‚                          â”‚   â”‚
â”‚                  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚   â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                      â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                              â”‚               â”‚                              â”‚
â”‚                              â”‚   LLM JUDGE   â”‚ â—€â”€â”€ Cannot see pixels!       â”‚
â”‚                              â”‚  (The Blind)  â”‚     Only sees JSON           â”‚
â”‚                              â”‚               â”‚                              â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                      â”‚                                      â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                              â”‚    VERDICT    â”‚                              â”‚
â”‚                              â”‚ âœ… APPROVED   â”‚                              â”‚
â”‚                              â”‚ âŒ REJECTED   â”‚                              â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

### ğŸš€ Fail-Fast Architecture
- Blurry images are rejected **immediately** using cheap OpenCV math
- Saves compute by not running expensive models on obviously bad images

### ğŸ§  Smart Feature Extraction
| Tier | Technology | Features |
|------|------------|----------|
| **Tier 1** | YOLOv8 | Object detection, people detection, subject area |
| **Tier 2** | CLIP | Scene type, photography style, background complexity |
| **Tier 3** | OpenCV | Sharpness, exposure, text/watermark detection |

### ğŸ¯ Region-Aware Blur Detection
- Distinguishes **intentional bokeh** (sharp subject, blurry background) from **actual blur**
- Analyzes the detected subject region, not the whole image

### âš–ï¸ Intelligent LLM Judge
- Applies a comprehensive **Rulebook** for consistent decisions
- Automatic retry with error recovery for malformed responses
- Mock mode for testing without API costs

## ğŸ“ Project Structure

```
â”œâ”€â”€ .idx/
â”‚   â””â”€â”€ dev.nix              # Nix config for Google Project IDX
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py            # Configuration (thresholds, model settings)
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cv_ops.py        # OpenCV operations (blur, exposure, text)
â”‚   â”‚   â”œâ”€â”€ vision_models.py # SINGLETON YOLO & CLIP wrappers
â”‚   â”‚   â””â”€â”€ pipeline.py      # FACADE orchestrator (consolidate_features)
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prompts.py       # System prompts for Blind Judge
â”‚   â”‚   â””â”€â”€ judge.py         # RETRY logic & LLM caller
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py       # Image utilities, file handling
â”œâ”€â”€ app.py                   # Streamlit UI
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation

### Option 1: Google Project IDX (Recommended)

1. Open project in IDX - the Nix environment will auto-configure
2. Wait for the workspace to initialize
3. The Streamlit preview will start automatically

### Option 2: Local Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd Artikate-Studio

# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (Linux/Mac)
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the application
streamlit run app.py
```

## ğŸš€ Usage

### Single Image Analysis

1. Upload an image using the file uploader
2. Click **"Analyze Image"**
3. View the verdict, warnings, and quality score
4. Expand **"View Extracted Features"** to see the JSON the LLM received

### Batch Processing

1. Enter a folder path containing product images
2. Optionally check "Include subfolders"
3. Click **"Process Folder"**
4. View results in the interactive table
5. Export as CSV or JSON

## ğŸ”§ Configuration

### Quality Thresholds

Adjust in `src/config.py` or via the Streamlit sidebar:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `fail_fast_sharpness` | 30.0 | Minimum sharpness to proceed |
| `sharpness_sharp` | 100.0 | Threshold for "Sharp" category |
| `sharpness_soft` | 50.0 | Threshold for "Soft" category |
| `min_subject_area_percent` | 10.0 | Minimum product area |

### LLM Providers

Set in the sidebar or code:

- `mock` - Local rule-based mock (no API costs)
- `openai` - OpenAI GPT-4 (requires API key)
- `gemini` - Google Gemini (requires API key)

## ğŸ“Š JSON Feature Schema

The system extracts exactly this schema:

```json
{
  "objects_detected": ["shoe", "shoebox"],
  "object_count": 2,
  "has_people": false,
  "primary_object_area_percent": 45.2,
  
  "clip_scene_type": "studio_product",
  "clip_style": "professional",
  "background_complexity": "minimal",
  
  "sharpness_score": 78.5,
  "sharpness_category": "Sharp",
  "exposure_category": "Well-Exposed",
  "text_detected": false
}
```

## ğŸ—ï¸ Design Patterns

| Pattern | Implementation | Purpose |
|---------|----------------|---------|
| **Singleton** | `vision_models.py` | Load YOLO/CLIP once, reuse for all images |
| **Facade** | `pipeline.py` | Simple `consolidate_features()` hides complexity |
| **Retry** | `judge.py` | Automatic retry with error context for LLM |

## ğŸ“ The Rulebook

The LLM Judge applies these rules in order:

### Automatic Rejection
- âŒ Blurry subject (`sharpness_category == "Blurry"`)
- âŒ People in product image (`has_people == true`)
- âŒ Subject too small (`primary_object_area_percent < 10%`)
- âŒ Watermarks detected (`text_detected == true`)

### Quality Warnings
- âš ï¸ Soft focus
- âš ï¸ Exposure issues
- âš ï¸ Complex background
- âš ï¸ Amateur style

### Quality Bonuses
- ğŸŒŸ Professional studio photography
- ğŸŒŸ Clean, minimal background

## ğŸ”’ License

MIT License - See LICENSE file for details.

---

<div align="center">

**Built with â¤ï¸ using Streamlit â€¢ YOLOv8 â€¢ CLIP â€¢ OpenCV**

</div>
